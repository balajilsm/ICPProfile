# -*- coding: utf-8 -*-
"""ICP_ML_ICP_JSON.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GsZzCTQGOqa5OUvXlNBqZDevQHfjQOVu

# ICP JSON Generator (XGBoost-ready)

This notebook reads your **real employee dataset (CSV)** and produces an ICP JSON in the exact structure you specified.

**What you get**
1. Clean config cell to map your column names
2. Data loading & validation
3. Top-performer derivation via thresholds
4. Role snapshot + skill means (1–5 scale)
5. Optional XGBoost model fit & feature importances
6. Final JSON saved to disk

> Tip: If you are in Colab, run the install cell first (it is safe to re-run).
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Optional installs (safe to skip if already installed)
try:
    import xgboost  # noqa: F401
except Exception:
#     %pip -q install xgboost scikit-learn
    import xgboost  # noqa: F401

import pandas as pd
import numpy as np
from typing import Dict, Any, List
from collections import Counter
from pathlib import Path
from statistics import mode
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from xgboost import XGBClassifier

"""## 1) Configuration — set your dataset path and map columns
Update **`CSV_PATH`** and the `COLS` mapping below to match your dataset. Only listed columns are required.

"""

### === REQUIRED: set your CSV path ===
# Example: if using Colab + Drive, mount then set the path like
# CSV_PATH = "/content/drive/MyDrive/hr/employee_icp.csv"
CSV_PATH = "/content/drive/MyDrive/Indeed/emp_history_data2.csv"  # <-- change me

### === REQUIRED: position to compute ICP for ===
POSITION_NAME = "HR Analyst"  # e.g., "HR Analyst", "Data Engineer", etc.

### === REQUIRED: map your column names here ===
COLS: Dict[str, str] = {
    # entity
    "employee_id": "employee_id",          # unique id
    "position": "position",                # job/role title

    # numeric experiences in years
    "total_experience_years": "total_experience_years",
    "role_experience_years": "role_experience_years",
    "tenure_years": "tenure_years",

    # education & certs
    "education": "education",              # categorical text
    "certifications_count": "certifications_count",  # int

    # location (text)
    "location": "location",

    # performance & KPI
    "performance_rating": "performance_rating",   # float (1–5)
    "kpi_score": "kpi_score",                     # numeric (0–100 ideally)

    # skills on 1–5 scale (add/remove as needed)
    "sql": "sql",
    "power_bi": "power_bi",
    "excel": "excel",
    "python": "python",
}

# You can add more skills: just add to COLS and SKILL_KEYS
SKILL_KEYS: List[str] = ["sql", "power_bi", "excel", "python"]

# Thresholds
PERF_MIN = 4.0            # performance_rating_min
KPI_TOP_QUANTILE = 0.75   # kpi_top_quantile

# Output path
OUTPUT_JSON_PATH = f"icp_{POSITION_NAME.lower().replace(' ', '_')}.json"

"""## 2) Helper functions

"""

from typing import Optional

def check_required_columns(df: pd.DataFrame, mapping: Dict[str, str]) -> None:
    missing = [v for v in mapping.values() if v not in df.columns]
    if missing:
        raise ValueError(f"Missing columns in CSV: {missing}\n\nPresent columns: {sorted(df.columns.tolist())}")

def safe_mode(series: pd.Series) -> Optional[str]:
    series = series.dropna()
    if series.empty:
        return None
    try:
        return series.mode(dropna=True).iloc[0]
    except Exception:
        counts = Counter(series)
        return counts.most_common(1)[0][0] if counts else None

def percent_with_certifications(series: pd.Series) -> float:
    series = pd.to_numeric(series, errors='coerce').fillna(0)
    return 100.0 * (series > 0).mean()

def bin_range_str(value: float, step: float, unit: str = "Years", left: float = 0, right: float = None) -> str:
    """Create a simple human-friendly range around a numeric value.
    Example: value=6.1, step=2 => "5-7 Years".
    """
    if value is None or np.isnan(value):
        return "N/A"
    lo = max(left, step * np.floor(value / step))
    hi = (lo + step)
    if right is not None:
        hi = min(hi, right)
    if unit:
        return f"{int(lo)}-{int(hi)} {unit}"
    return f"{lo}-{hi}"

def rating_range_str(value: float, step: float = 0.5, max_val: float = 5.0) -> str:
    if value is None or np.isnan(value):
        return "N/A"
    lo = step * np.floor(value / step)
    hi = min(lo + step, max_val)
    return f"{lo:.1f}-{hi:.0f}" if hi.is_integer() else f"{lo:.1f}-{hi:.1f}"

def score_range_str(value: float, step: float = 5.0, max_val: float = 100.0) -> str:
    if value is None or np.isnan(value):
        return "N/A"
    lo = step * np.floor(value / step)
    hi = min(lo + step, max_val)
    return f"{int(lo)}-{int(hi)}"

def build_icp_json(
    *,
    position: str,
    counts: Dict[str, int],
    thresholds_used: Dict[str, float],
    role_snapshot: Dict[str, Any],
    skills_means_1_to_5: Dict[str, Any],
) -> Dict[str, Any]:
    return {
        "position": position,
        "counts": {
            "total_employees": int(counts.get("total_employees", 0)),
            "top_performers": int(counts.get("top_performers", 0)),
        },
        "thresholds_used": {
            "performance_rating_min": thresholds_used.get("performance_rating_min"),
            "kpi_top_quantile": thresholds_used.get("kpi_top_quantile"),
        },
        "role_snapshot": {
            "avg_total_experience_years": role_snapshot.get("avg_total_experience_years"),
            "avg_role_experience_years": role_snapshot.get("avg_role_experience_years"),
            "avg_tenure_years": role_snapshot.get("avg_tenure_years"),
            "education_mode": role_snapshot.get("education_mode"),
            "percent_with_certifications": role_snapshot.get("percent_with_certifications"),
            "top_location": role_snapshot.get("top_location"),
            "avg_performance_rating": role_snapshot.get("avg_performance_rating"),
            "avg_kpi_score": role_snapshot.get("avg_kpi_score"),
        },
        "skills_means_1_to_5": skills_means_1_to_5,
    }

"""## 3) Load data & validate

"""

df = pd.read_csv(CSV_PATH)
check_required_columns(df, COLS)
print(f"Loaded {len(df):,} rows from {CSV_PATH}")

# If a position column is present, filter to this role
if COLS.get("position") in df.columns:
    df_role = df[df[COLS["position"]] == POSITION_NAME].copy()
    if df_role.empty:
        raise ValueError(f"No rows found for POSITION_NAME='{POSITION_NAME}'. \n"
                         f"Check your POSITION_NAME or the '{COLS['position']}' column values.")
else:
    df_role = df.copy()

print(f"Rows for role '{POSITION_NAME}': {len(df_role):,}")

"""## 4) Derive top performers using thresholds
Top performers are those with `performance_rating >= PERF_MIN` and `kpi_score >= KPI 75th percentile` (within the role).
"""

perf_col = COLS["performance_rating"]
kpi_col = COLS["kpi_score"]

perf = pd.to_numeric(df_role[perf_col], errors='coerce')
kpi = pd.to_numeric(df_role[kpi_col], errors='coerce')

kpi_threshold = np.nanquantile(kpi, KPI_TOP_QUANTILE)
is_top = (perf >= PERF_MIN) & (kpi >= kpi_threshold)

total_employees = int(len(df_role))
top_performers = int(is_top.sum())
print({"total_employees": total_employees, "top_performers": top_performers, "kpi_threshold": float(kpi_threshold)})

"""## 5) Compute role snapshot (ranges & modes)"""

tot_exp = pd.to_numeric(df_role[COLS["total_experience_years"]], errors='coerce').mean()
role_exp = pd.to_numeric(df_role[COLS["role_experience_years"]], errors='coerce').mean()
tenure = pd.to_numeric(df_role[COLS["tenure_years"]], errors='coerce').mean()

edu_mode = safe_mode(df_role[COLS["education"]])
cert_pct = percent_with_certifications(df_role[COLS["certifications_count"]])
loc_mode = safe_mode(df_role[COLS["location"]])

avg_perf = pd.to_numeric(df_role[perf_col], errors='coerce').mean()
avg_kpi = pd.to_numeric(df_role[kpi_col], errors='coerce').mean()

role_snapshot = {
    "avg_total_experience_years": bin_range_str(tot_exp, step=2, unit="Years"),
    "avg_role_experience_years": bin_range_str(role_exp, step=2, unit="Years"),
    "avg_tenure_years": bin_range_str(tenure, step=2, unit="Years"),
    "education_mode": edu_mode if edu_mode is not None else "N/A",
    "percent_with_certifications": f">={int(round(cert_pct))}",
    "top_location": loc_mode if loc_mode is not None else "N/A",
    "avg_performance_rating": rating_range_str(avg_perf, step=0.5, max_val=5.0),
    "avg_kpi_score": score_range_str(avg_kpi, step=5.0, max_val=100.0),
}
role_snapshot

"""## 6) Compute skills means (1–5 scale)
By default this averages **top performers only** (better for ICP). Set `USE_TOP_PERFORMERS_ONLY=False` to average all.
"""

USE_TOP_PERFORMERS_ONLY = True

if USE_TOP_PERFORMERS_ONLY and top_performers > 0:
    df_skills_base = df_role[is_top].copy()
else:
    df_skills_base = df_role.copy()

skills_means: Dict[str, Any] = {}
for key in SKILL_KEYS:
    col = COLS[key]
    mean_val = pd.to_numeric(df_skills_base[col], errors='coerce').mean()
    if np.isnan(mean_val):
        skills_means[key] = "N/A"
    else:
        # express as a small range around the mean (±0.5), clipped to [1,5]
        lo = max(1.0, round(mean_val - 0.5, 1))
        hi = min(5.0, round(mean_val + 0.5, 1))
        # avoid identical lo/hi like 4.0-4.0
        if abs(hi - lo) < 1e-6:
            hi = min(5.0, lo + 0.5)
        skills_means[key] = f"{lo}-{hi}"

skills_means

"""## 7) Build & save ICP JSON (exact structure)"""

payload = build_icp_json(
    position=POSITION_NAME,
    counts={"total_employees": total_employees, "top_performers": top_performers},
    thresholds_used={"performance_rating_min": float(PERF_MIN), "kpi_top_quantile": float(KPI_TOP_QUANTILE)},
    role_snapshot=role_snapshot,
    skills_means_1_to_5=skills_means,
)

with open(OUTPUT_JSON_PATH, "w", encoding="utf-8") as f:
    json.dump(payload, f, ensure_ascii=False, indent=2)

print(f"Saved ICP JSON to: {OUTPUT_JSON_PATH}")
print(json.dumps(payload, indent=2))

"""## 8) (Optional) Train a quick XGBoost model
Creates a training target from the same thresholds. If you already have a label, replace `y` with your label column.
"""

try:
    # Features = experiences + skills + KPI (you can customize)
    feat_cols = [
        COLS["total_experience_years"], COLS["role_experience_years"], COLS["tenure_years"],
        *[COLS[k] for k in SKILL_KEYS],
        COLS["kpi_score"],
    ]
    X = df_role[feat_cols].apply(pd.to_numeric, errors='coerce').fillna(0.0).values
    y = is_top.astype(int).values

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)
    clf = XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, subsample=0.9, colsample_bytree=0.9, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(classification_report(y_test, y_pred, digits=3))
except Exception as e:
    print("XGBoost training skipped:", e)